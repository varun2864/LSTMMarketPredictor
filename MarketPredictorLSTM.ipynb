{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_igW2IGz2Ca",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install ta\n",
        "!pip install scikeras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn==1.4.2"
      ],
      "metadata": {
        "id": "ZqDR6l11ojWI",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ta\n",
        "import yfinance as yf\n",
        "n50 = yf.Ticker(\"^NSEI\")\n",
        "\n",
        "n50 = n50.history(period = \"max\")"
      ],
      "metadata": {
        "id": "Eb3VR1xQ0Any"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del n50[\"Dividends\"]\n",
        "del n50[\"Stock Splits\"]\n",
        "n50 = n50[n50[\"Volume\"]!=0]"
      ],
      "metadata": {
        "id": "iTAWeLy00Ffh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n50[\"tomorrow\"] = n50[\"Close\"].shift(-1)\n",
        "n50[\"target\"] = (n50[\"tomorrow\"]>n50[\"Close\"]).astype(int)\n",
        "\n",
        "'''\n",
        "n50[\"RSI\"] = ta.momentum.rsi(n50[\"Close\"], window = 14)\n",
        "\n",
        "macd = ta.trend.MACD(n50[\"Close\"], window_slow=26, window_fast=12, window_sign=9)\n",
        "n50[\"MACD\"] = macd.macd() #calculates main macd line, confusing variable name\n",
        "n50[\"MACD_signal\"] = macd.macd_signal()\n",
        "\n",
        "bb = ta.volatility.BollingerBands(close=n50[\"Close\"], window=20, window_dev=2)\n",
        "n50[\"BB_high\"] = bb.bollinger_hband()\n",
        "n50[\"BB_low\"] = bb.bollinger_lband()\n",
        "\n",
        "n50[\"EMA_F\"] = ta.trend.ema_indicator(close = n50[\"Close\"], window = 50)\n",
        "n50[\"EMA_S\"] = ta.trend.ema_indicator(close = n50[\"Close\"], window = 200)\n",
        "'''"
      ],
      "metadata": {
        "id": "Se1H73Mb0He3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n50 = n50.dropna()"
      ],
      "metadata": {
        "id": "9AbLE8b50KG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n50"
      ],
      "metadata": {
        "id": "q8VgEn122Ba-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "\n",
        "scaler  = MinMaxScaler()\n",
        "predictors_n50 = [\"Volume\", \"High\", \"Close\", \"Open\", \"Low\"]\n",
        "\n",
        "horizons = [2, 5, 60, 260, 1000]\n",
        "#new_predictors = []\n",
        "\n",
        "for horizon in horizons:\n",
        "  rolling_avgs = n50.rolling(horizon).mean()\n",
        "\n",
        "  ratio_col = f\"Close_Ratio_{horizon}\"\n",
        "  n50[ratio_col] = n50[\"Close\"] / rolling_avgs[\"Close\"]\n",
        "\n",
        "  trend_col = f\"Trend_{horizon}\"\n",
        "  n50[trend_col] = n50.shift(1).rolling(horizon).sum()[\"target\"]\n",
        "\n",
        "  predictors_n50 += [ratio_col, trend_col]\n",
        "\n",
        "n50 = n50.dropna()\n",
        "n50[predictors_n50] = scaler.fit_transform(n50[predictors_n50])"
      ],
      "metadata": {
        "id": "4BpdV4Oj0M7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def sequences(data, target, time_steps = 10):\n",
        "  data_seq = []\n",
        "  target_seq = []\n",
        "  for i in range(len(data) - time_steps):\n",
        "    data_seq.append(data.iloc[i:(i+time_steps)].values)\n",
        "    target_seq.append(target.iloc[i+time_steps])\n",
        "  return np.array(data_seq), np.array(target_seq)"
      ],
      "metadata": {
        "id": "HPcsk7XE0SAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(units = 150, dropout_rate = 0.1, batch_size = 128, epochs = 10):\n",
        "  model = Sequential()\n",
        "  model.add(Input(shape = (x_train.shape[1], x_train.shape[2])))\n",
        "  model.add(LSTM(units, return_sequences = True))\n",
        "  model.add(Dropout(dropout_rate))\n",
        "  model.add(LSTM(units = units))\n",
        "  model.add(Dropout(dropout_rate))\n",
        "  model.add(Dense(units = 1, activation = \"sigmoid\"))\n",
        "  model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
        "  return model"
      ],
      "metadata": {
        "id": "xztNprMm0hAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = sequences(n50[predictors_n50], n50[\"target\"], time_steps = 10)\n",
        "\n",
        "x_train_val, x_test, y_train_val, y_test = train_test_split(x, y, test_size=0.1, random_state=1)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.1, random_state=1)"
      ],
      "metadata": {
        "id": "E74LQWWNroIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = KerasClassifier(model=create_model, units=200, dropout_rate=0.1, batch_size=128, epochs=10)\n",
        "results = model.fit(x_train, y_train, validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "id": "Y9un3HpGwPHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = model.score(x_test, y_test)\n",
        "print(f\"accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "NVvGgs37rkIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_test)\n",
        "precision = precision_score(y_test, predictions)\n",
        "print(f\"precision: {precision}\")"
      ],
      "metadata": {
        "id": "kmcWDmqFwQqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prec = 0\n",
        "\n",
        "for i in range(len(predictions)):\n",
        "    if predictions[i] == y_test[i]:\n",
        "      prec = prec+1\\\n",
        "\n",
        "print(prec/len(y_test))"
      ],
      "metadata": {
        "id": "VI1cIGEuzKkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score, f1_score\n",
        "\n",
        "recall = recall_score(y_test, predictions)\n",
        "print(f\"Recall: {recall}\")\n",
        "\n",
        "f1 = f1_score(y_test, predictions)\n",
        "print(f\"F1 Score: {f1}\")"
      ],
      "metadata": {
        "id": "JXuRbP3T5D0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'model__units': [50, 100, 150],\n",
        "    'model__dropout_rate': [0.1, 0.2, 0.3],\n",
        "    'batch_size': [32, 64, 128],\n",
        "    'epochs': [10, 20, 30]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
        "grid_result = grid.fit(x_train, y_train)\n",
        "\n",
        "_, accuracy = grid_result.best_estimator_.model_.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "print(f\"Best Accuracy: {accuracy}\")\n",
        "print(f\"Best Parameters: {grid_result.best_params_}\")\n",
        "\n",
        "#output with indicators came to be 150 units, 0.1 dropout rate, 10 epochs, 128 batch size"
      ],
      "metadata": {
        "id": "f0NtuLDX1OSU",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}